# A revised and improved version of the GitHub Actions workflow.
# Key changes:
# 1. SAFER TAGGING: The "Update tag" step is now restricted to only run on dev builds.
# 2. CLEANER PERMISSIONS: Removed the unused "discussions: write" permission.
# 3. ROBUST DEV VERSIONING: The .devN suffix is now calculated by incrementing the last dev tag for the current version base.
# 4. MINOR CLEANUP: Added comments and removed redundant steps for clarity.

name: build

on:
  push:
    branches: ["main"]
    paths:
      - '**.go'
      - '**.ts'
      - '**.tsx'
      - '**.py'
      - '**/go.mod'
      - '**/go.sum'
      - '**/package.json'
      - '**/bun.lockb'
      - '**/Makefile'
      - 'bun.build.ts'
      - 'custom_components/**'
      - 'hacs.json'
      - '.github/workflows/build.yaml'
  release:
    types: ["published"]
  pull_request:
    branches: ["main"]

# Permissions: Removed 'discussions: write' as it was unused.
permissions:
  contents: write

jobs:
  setversion:
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.calculate_version.outputs.version }}
    name: Set version
    steps:
      - name: Checkout the repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0 # fetch-depth: 0 is required for git commands to see all history/tags

      - name: Calculate version
        id: calculate_version
        run: |
          set -euo pipefail

          if [[ "${{ github.event_name }}" == "release" && "${{ github.event.action }}" == "published" ]]; then
            VERSION="${{ github.event.release.tag_name }}"
            echo "Using release tag as version: $VERSION"
          else
            # Dev build version calculation
            CURRENT_YEAR=$(date -u +'%Y')
            CURRENT_MONTH=$(date -u +'%-m')
            CURRENT_PERIOD_PREFIX="${CURRENT_YEAR}.${CURRENT_MONTH}"

            echo "Fetching non-draft release tags for period ${CURRENT_PERIOD_PREFIX}..."
            # Get all tag_names from non-draft (published or pre-release) GitHub releases.
            # The `|| echo ""` ensures the script doesn't fail if gh api returns error or no releases.
            ALL_NON_DRAFT_RELEASE_TAGS_STRING=$(gh api --paginate /repos/${{ github.repository }}/releases -q '.[] | select(.draft == false) | .tag_name' || echo "")

            FILTERED_TAGS_LIST=()
            if [[ -n "$ALL_NON_DRAFT_RELEASE_TAGS_STRING" ]]; then
              while IFS= read -r tag; do
                # Ensure tag is not empty and matches the YYYY.M.* pattern for the current period.
                # This regex also ensures it's either a full release (YYYY.M.INC) or a dev release tag (YYYY.M.INC-dev.DEV).
                if [[ -n "$tag" && "$tag" =~ ^${CURRENT_PERIOD_PREFIX}\.([0-9]+)(-dev\.([0-9]+))?$ ]]; then
                  FILTERED_TAGS_LIST+=("$tag")
                fi
              done <<< "$ALL_NON_DRAFT_RELEASE_TAGS_STRING"
            fi

            TAGS_SORTED_STRING=""
            if [ ${#FILTERED_TAGS_LIST[@]} -gt 0 ]; then
              TAGS_SORTED_STRING=$(printf "%s\n" "${FILTERED_TAGS_LIST[@]}" | sed '/-/!{s/$/_/}' | sort -V | sed 's/_$//')
              echo "Found and sorted relevant tags from non-draft releases:"
              echo "${TAGS_SORTED_STRING}"
            else
              echo "No relevant non-draft release tags found for ${CURRENT_PERIOD_PREFIX} matching the versioning pattern."
            fi

            MAX_INC=-1 # Stores the 'INC' part of YYYY.M.INC or YYYY.M.INC-dev.N
            MAX_DEV_FOR_MAX_INC=-1 # Stores the 'DEV' part for the current MAX_INC if it's a dev series
            MAX_INC_IS_FULL_RELEASE=false # Flag to track if MAX_INC corresponds to a full release tag

            # Iterate over the sorted list of tags obtained from published releases.
            # If TAGS_SORTED_STRING is empty, this loop will not run.
            for TAG in $TAGS_SORTED_STRING; do
              if [[ "$TAG" =~ ^${CURRENT_PERIOD_PREFIX}\.([0-9]+)$ ]]; then # Matches a full release tag pattern: YYYY.M.INC
                INC=${BASH_REMATCH[1]}
                if (( INC > MAX_INC )); then
                  MAX_INC=$INC
                  MAX_DEV_FOR_MAX_INC=-1 # Reset dev part as this is a new, higher INC from a full release
                  MAX_INC_IS_FULL_RELEASE=true
                elif (( INC == MAX_INC )); then
                  # Encountered a full release tag for the current MAX_INC.
                  # This means this INC is finalized as a full release, overriding any prior dev status for this INC.
                  MAX_INC_IS_FULL_RELEASE=true
                  MAX_DEV_FOR_MAX_INC=-1 # Reset dev part
                fi
              elif [[ "$TAG" =~ ^${CURRENT_PERIOD_PREFIX}\.([0-9]+)-dev\.([0-9]+)$ ]]; then # Matches a dev tag pattern: YYYY.M.INC-dev.DEV
                INC=${BASH_REMATCH[1]}
                DEV=${BASH_REMATCH[2]}
                if (( INC > MAX_INC )); then
                  MAX_INC=$INC
                  MAX_DEV_FOR_MAX_INC=$DEV
                  MAX_INC_IS_FULL_RELEASE=false # This new MAX_INC is established by a dev tag
                elif (( INC == MAX_INC )); then
                  # Processing a dev tag for the current MAX_INC.
                  if $MAX_INC_IS_FULL_RELEASE; then
                    # MAX_INC was previously considered a full release (e.g., 2024.7.1 was processed).
                    # Now seeing a dev tag for it (e.g., 2024.7.1-dev.0).
                    # This means we're starting a dev series *for* this MAX_INC.
                    MAX_INC_IS_FULL_RELEASE=false # Mark that this INC is now on a dev track
                    MAX_DEV_FOR_MAX_INC=$DEV      # Start counting dev from this tag's DEV value
                  elif (( DEV > MAX_DEV_FOR_MAX_INC )); then
                    # Continue on the dev track for MAX_INC (MAX_INC_IS_FULL_RELEASE was already false)
                    MAX_DEV_FOR_MAX_INC=$DEV
                  fi
                fi
              fi
            done

            if (( MAX_INC == -1 )); then
              # No tags found for the current YYYY.MM period (e.g., 2024.7.*). Start with .0-dev.0.
              VERSION="${CURRENT_PERIOD_PREFIX}.0-dev.0"
            else
              if $MAX_INC_IS_FULL_RELEASE; then
                # The latest version component (MAX_INC) for this period was a full release (e.g., 2024.7.1).
                # So, the next dev version should increment the INC part and start with -dev.0.
                VERSION="${CURRENT_PERIOD_PREFIX}.$((MAX_INC + 1))-dev.0"
              else
                # The latest version component (MAX_INC) for this period was a dev series (e.g., 2024.7.1-dev.3).
                # So, increment the dev suffix for the current MAX_INC.
                VERSION="${CURRENT_PERIOD_PREFIX}.${MAX_INC}-dev.$((MAX_DEV_FOR_MAX_INC + 1))"
              fi
            fi
            echo "Calculated dev version: $VERSION"
          fi
          echo "Calculated version: $VERSION"
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  test-backend:
    name: Test Backend
    runs-on: ubuntu-latest
    needs: setversion
    outputs:
      coverage: ${{ steps.extract_coverage.outputs.backend_coverage }}
    steps:
      - name: Checkout the repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0

      - name: Setup go
        uses: actions/setup-go@7a3fe6cf4cb3a834922a1244abfce67bcef6a0c5 # v6.2.0
        with:
          go-version-file: 'backend/src/go.mod'
          cache-dependency-path: "**/*.sum"

      - name: Prepare backend for ${{ needs.setversion.outputs.version }}
        run: |       
          cd backend
          make patch format
          cd ..

      - name: Test Backend ${{ needs.setversion.outputs.version }}
        # RECOMMENDATION: Investigate if 'sudo' is truly necessary for tests.
        # Running tests as root is a potential security risk.
        id: test_backend
        run: |
          set -o pipefail
          cd backend
          sudo -E PATH="$PATH" make test 2>&1 | tee backend_test_output.txt

      - name: Extract Backend Coverage
        id: extract_coverage
        run: |
          COVERAGE_LINE=$(grep "Total coverage:" backend/backend_test_output.txt | tail -1 || true)
          if [ -n "$COVERAGE_LINE" ]; then
            COVERAGE=$(echo "$COVERAGE_LINE" | awk '{gsub(/%/, "", $3); print $3}')
          else
            COVERAGE="0.0"
          fi
          echo "backend_coverage=$COVERAGE" >> "$GITHUB_OUTPUT"
          echo "Backend Coverage: $COVERAGE%"

      - name: Save Backend Coverage Report
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: backend-coverage-report
          path: ./backend/src/coverage.out
          
  test-frontend:
    name: Test Frontend
    runs-on: ubuntu-latest
    needs: setversion
    outputs:
      coverage: ${{ steps.extract_coverage.outputs.frontend_coverage }}
    steps:
      - name: Checkout the repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0

      - uses: oven-sh/setup-bun@3d267786b128fe76c2f16a390aa2448b815359f3 # v2
        with:
          bun-version-file: frontend/package.json

      - name: Prepare frontend for ${{ needs.setversion.outputs.version }}
        run: |       
          cd frontend
          bun install

      - name: Test Frontend ${{ needs.setversion.outputs.version }}
        id: test_frontend
        run: |
          set -o pipefail
          echo "Verifying setup.ts content before running tests (post-install):"
          if [ -f frontend/test/setup.ts ]; then
            echo "SHA1 and path for frontend/test/setup.ts:" && sha1sum frontend/test/setup.ts || true
            echo "Preview (first 20 lines):" && sed -n '1,20p' frontend/test/setup.ts || true
          else
            echo "frontend/test/setup.ts not found (pwd: $(pwd))"
            ls -la || true
          fi
          cd frontend
          bun test:ci --coverage-reporter=lcov 2>&1 | tee frontend_test_output.txt

      - name: Extract Frontend Coverage
        id: extract_coverage
        run: |
          COVERAGE_LINE=$(grep "All files" frontend/frontend_test_output.txt | tail -1 || true)
          if [ -n "$COVERAGE_LINE" ]; then
            COVERAGE=$(echo "$COVERAGE_LINE" | awk -F'|' '{gsub(/^[ \t]+|[ \t]+$/, "", $2); gsub(/%/, "", $2); print $2}')
          else
            COVERAGE="0.0"
          fi
          echo "frontend_coverage=$COVERAGE" >> "$GITHUB_OUTPUT"
          echo "Frontend Coverage: $COVERAGE%"

      - name: Save Frontend Coverage Report
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: frontend-coverage-report
          path: ./frontend/coverage/lcov.info

  test-custom-component:
    name: Test Custom Component
    runs-on: ubuntu-latest
    needs: setversion
    steps:
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - name: HACS Validation
        uses: hacs/action@main
        with:
          category: integration
          ignore: brands

      - name: hassfest Validation
        uses: home-assistant/actions/hassfest@master

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.14"

      - name: Install dev dependencies
        run: make -C custom_components install-pip

      - name: Ruff format check
        run: make -C custom_components format-check

      - name: Ruff lint
        run: make -C custom_components lint

      - name: Mypy type check
        run: make -C custom_components typecheck

      - name: Run tests
        run: make -C custom_components test-ci

      - name: Upload Custom Component Coverage Report
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: custom-component-coverage-report
          path: custom_components/coverage.xml

  update-coverage:
    name: Update Coverage Badges
    runs-on: ubuntu-latest
    needs: [setversion, test-backend, test-frontend, test-custom-component, build]
    permissions:
      contents: write
    steps:
      - name: Checkout the repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Restore Backend Coverage Report
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7
        with:
          name: backend-coverage-report

      - name: Upload Backend Coverage to Codecov
        uses: codecov/codecov-action@671740ac38dd9b0130fbe1cec585b89eea48d3de # v5.5.2
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./backend/src/coverage.out
          flags: backend
          name: backend-coverage
          fail_ci_if_error: false

      - name: Restore Frontend Coverage Report
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7
        with:
          name: frontend-coverage-report

      - name: Upload Frontend Coverage to Codecov
        uses: codecov/codecov-action@671740ac38dd9b0130fbe1cec585b89eea48d3de # v5.5.2
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./frontend/coverage/lcov.info
          flags: frontend
          name: frontend-coverage
          fail_ci_if_error: false

      - name: Restore Custom Component Coverage Report
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7
        with:
          name: custom-component-coverage-report

      - name: Upload Custom Component Coverage to Codecov
        uses: codecov/codecov-action@671740ac38dd9b0130fbe1cec585b89eea48d3de # v5.5.2
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./custom_components/coverage.xml
          flags: custom-component
          name: custom-component-coverage
          fail_ci_if_error: false

  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [setversion, test-backend, test-frontend, test-custom-component]
    env:
      ROLLBAR_CLIENT_ACCESS_TOKEN: ${{ secrets.ROLLBAR_CLIENT_ACCESS_TOKEN || 'disabled' }}
      GIST_TOKEN: ${{ secrets.GIST_TOKEN || 'disabled' }}
      ROLLBAR_ENVIRONMENT: "production"
    steps:
      - name: Checkout the repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0

      - name: Setup go
        uses: actions/setup-go@7a3fe6cf4cb3a834922a1244abfce67bcef6a0c5 # v6.2.0
        with:
          go-version-file: 'backend/src/go.mod'
          cache-dependency-path: "**/*.sum"

      - uses: oven-sh/setup-bun@3d267786b128fe76c2f16a390aa2448b815359f3 # v2
        with:
          bun-version-file: frontend/package.json

      - name: Prepare env for ${{ needs.setversion.outputs.version }}
        run: |       
          cd backend
          make patch format
          cd ../frontend
          bun install
          cd ..

      - name: Set custom component version
        run: |
          VERSION="${{ needs.setversion.outputs.version }}"
          # Strip -dev.N suffix for HA manifest (requires strict YYYY.MM.PATCH semver)
          MANIFEST_VERSION=$(echo "$VERSION" | sed 's/-dev\.[0-9]*//')
          echo "Setting custom component version to: $MANIFEST_VERSION"
          jq --arg v "$MANIFEST_VERSION" '.version = $v' custom_components/srat/manifest.json > /tmp/manifest.json
          mv /tmp/manifest.json custom_components/srat/manifest.json

      - name: Check if tag ${{ needs.setversion.outputs.version }} exists
        if: github.event_name != 'pull_request'
        id: checkTag
        uses: mukunku/tag-exists-action@5c39604fe8aef7e65acb6fbcf96ec580f7680313 # v1.7.0
        with:
          tag: '${{ needs.setversion.outputs.version }}'

      - name: Update dev tag ${{ needs.setversion.outputs.version }}
        # CRITICAL IMPROVEMENT: This step is now safer.
        # It will ONLY run if the tag already exists AND it's a dev build (version contains '.dev').
        # This prevents accidentally moving a final release tag.
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8
        if: |
          github.event_name != 'pull_request' &&
          steps.checkTag.outputs.exists == 'true' &&
          contains(needs.setversion.outputs.version, '-dev')
        with:
          script: |
            github.rest.git.updateRef({
              owner: context.repo.owner,
              repo: context.repo.repo,
              ref: 'tags/${{ needs.setversion.outputs.version }}',
              sha: context.sha,
              force: true
            })

      - name: Create tag ${{ needs.setversion.outputs.version }}
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8
        if: ${{ github.event_name != 'pull_request' && steps.checkTag.outputs.exists == 'false' }}
        with:
          script: |
            github.rest.git.createRef({
              owner: context.repo.owner,
              repo: context.repo.repo,
              ref: 'refs/tags/${{ needs.setversion.outputs.version }}',
              sha: context.sha
            })

      #- uses: mlugg/setup-zig@d1434d08867e3ee9daa34448df10607b98908d29 # v2
      #  with:
      #    version: '0.14.1'
            
      - name: BuildAll
        id: built_all
        if: github.event_name != 'pull_request'
        env:
          CGO_ENABLED: 0  # Explicitly disable CGO for static builds
        run: |
          sudo -E PATH="$PATH" make ALL VERSION=${{ needs.setversion.outputs.version }}

      - name: Sign binaries with Minisign
        if: github.event_name != 'pull_request'
        env:
          UPDATE_SIGNING_KEY: ${{ secrets.UPDATE_SIGNING_KEY }}
        run: |
          set -euo pipefail
          
          # Check if signing key is available
          if [ -z "$UPDATE_SIGNING_KEY" ]; then
            echo "âš ï¸  WARNING: UPDATE_SIGNING_KEY secret not found. Binaries will not be signed."
            echo "This is expected for forks and development branches."
            echo "Signature verification will be skipped during updates."
            exit 0
          fi
          
          # Install minisign using Alpine package manager
          echo "Installing minisign..."
          sudo apt-get update && sudo apt-get install -y minisign
          
          # Save private key to a temporary file
          PRIVATE_KEY_FILE=$(mktemp)
          echo "$UPDATE_SIGNING_KEY" > "$PRIVATE_KEY_FILE"
          chmod 600 "$PRIVATE_KEY_FILE"
          
          # Function to cleanup on exit
          cleanup() {
            rm -f "$PRIVATE_KEY_FILE"
          }
          trap cleanup EXIT
          
          # Sign each binary
          echo "Signing binaries with minisign..."
          for binary_path in backend/dist/*/srat-{cli,server,openapi}; do
            if [ -f "$binary_path" ]; then
              echo "Signing binary: $binary_path"
              
              # Create signature using minisign
              # The -s flag specifies the secret key file
              # The -m flag specifies the file to sign
              # The -x flag specifies the output signature file
              sudo minisign -SW \
                -s "$PRIVATE_KEY_FILE" \
                -m "$binary_path" \
                -x "./${binary_path}.minisig"
              
              echo "âœ… Signature created: ${binary_path}.minisig"
            else
              echo "âš ï¸ Binary not found: $binary_path"
            fi
          done
          
          echo "Binary signing complete"

      - name: Prepare temporary directory for zips
        if: github.event_name != 'pull_request'
        run: mkdir -p /tmp/build_artifacts

      - name: Find architectures and create zip archives
        id: create_zips
        if: github.event_name != 'pull_request'
        run: |
          set -euo pipefail
          # This script zips only binary files and attaches the corresponding minisig content as the file comment.
          for arch_dir in backend/dist/*/; do
            arch=$(basename "$arch_dir")
            zip_file_path="/tmp/build_artifacts/srat_${arch}.zip"
            echo "Processing architecture: ${arch}"

            if [ ! -d "$arch_dir" ]; then
              echo "Warning: Directory ${arch_dir} does not exist. Skipping."
              continue
            fi

            files_to_zip=()
            tmp_note_file=$(mktemp)

            # Collect binaries that have a matching minisig and prepare comments
            for bin_path in "$arch_dir"*; do
              [ -e "$bin_path" ] || continue

              # Skip directories
              if [ -d "$bin_path" ]; then
                continue
              fi

              base_name=$(basename "$bin_path")

              # Skip minisig files on this pass
              if [[ "$base_name" == *.minisig ]]; then
                continue
              fi

              minisig_path="${bin_path}.minisig"
              if [ -f "$minisig_path" ]; then
                files_to_zip+=("$base_name")
                {
                  echo "@ $base_name"
                  cat "$minisig_path"
                  echo "@"
                } >> "$tmp_note_file"
              else
                echo "Warning: Skipping ${base_name} because minisig file is missing."
              fi
            done

            # Warn about stray minisig files without matching binaries
            for minisig_path in "$arch_dir"*.minisig; do
              [ -e "$minisig_path" ] || continue
              bin_candidate="${minisig_path%.minisig}"
              if [ ! -f "$bin_candidate" ]; then
                echo "Warning: Skipping $(basename "$minisig_path") because matching binary is missing."
              fi
            done

            if [ ${#files_to_zip[@]} -eq 0 ]; then
              echo "Warning: No binaries with minisig found in ${arch_dir}. Skipping zip creation."
              rm -f "$tmp_note_file"
              continue
            fi

            (cd "$arch_dir" && zip -q "$zip_file_path" "${files_to_zip[@]}")

            if [ -s "$tmp_note_file" ]; then
              zipnote -w "$zip_file_path" < "$tmp_note_file" >/dev/null
            fi
            rm -f "$tmp_note_file"

            echo "Successfully created ${zip_file_path}"
            echo "Archive contents:"
            unzip -l "$zip_file_path"
          done

      - name: Upload binaries as artifact
        if: steps.built_all.conclusion == 'success'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: binary-builds
          path: /tmp/build_artifacts/*.zip
          retention-days: 7
          overwrite: true

      - name: Create HACS custom component zip
        if: github.event_name != 'pull_request'
        run: |
          cd custom_components/srat
          zip -r /tmp/build_artifacts/srat.zip . -x '__pycache__/*' '*.pyc'
          echo "HACS component zip created:"
          unzip -l /tmp/build_artifacts/srat.zip

      - name: Upload HACS component as artifact
        if: github.event_name != 'pull_request'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: hacs-component
          path: /tmp/build_artifacts/srat.zip
          retention-days: 7
          overwrite: true

  create-release:
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'
    needs: [build, setversion]
    steps:
      - name: Delete old draft releases
        uses: hugo19941994/delete-draft-releases@d375ad67d25fed7520a8020c3a6561fff5260c1e # v2.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Checkout repository for CHANGELOG extraction
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0

      - name: Extract Unreleased section from CHANGELOG
        id: extract_changelog
        run: |
          set -euo pipefail

          # Check if CHANGELOG.md exists
          if [[ ! -f "CHANGELOG.md" ]]; then
            echo "CHANGELOG.md not found, skipping extraction"
            echo "changelog_content=" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Extract content between "## [ ðŸš§ Unreleased ]" and next "##"
          # Using awk to extract the section
          CHANGELOG_CONTENT=$(awk '
            BEGIN { in_unreleased = 0; content = "" }
            /^## \[ ðŸš§ Unreleased \]/ { in_unreleased = 1; next }
            /^## / && in_unreleased { exit }
            in_unreleased {
              if (content != "") content = content "\n"
              content = content $0
            }
            END { print content }
          ' CHANGELOG.md)

          # Save to output using multiline string
          {
            echo "changelog_content<<EOF"
            echo "## What's Changed"
            echo ""
            echo "$CHANGELOG_CONTENT"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7
        id: download_art
        with:
          name: binary-builds
          path: /tmp/downloaded_builds

      - uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7
        id: download_hacs
        with:
          name: hacs-component
          path: /tmp/downloaded_builds

      - name: Create Release and Upload Assets
        if: github.event_name != 'release' || github.event.action != 'published' || !github.event.release.prerelease
        uses: softprops/action-gh-release@a06a81a03ee405af7f2048a818ed3f03bbf83c7b # v2
        with:
          tag_name: ${{ needs.setversion.outputs.version }}
          name: Release ${{ needs.setversion.outputs.version }}
          # Create a draft and pre-release for pushes to main, but a full release for 'release' events.
          draft: ${{ github.event_name != 'release' }}
          prerelease: ${{ github.event_name != 'release' || github.event.release.prerelease }}
          body: ${{ steps.extract_changelog.outputs.changelog_content }}
          generate_release_notes: true
          files: ${{ steps.download_art.outputs.download-path }}/*
